import os
import numpy as np
import streamlit as st
from io import BytesIO
import streamlit.components.v1 as components
import wave
import speech_recognition as sr
from async_trans import trans
from konlpy.tag import Hannanum
import pandas as pd
import asyncio
from notion_api_cnt import insert_data, get_pages


def st_audiorec():

    # get parent directory relative to current directory
    parent_dir = os.path.dirname(os.path.abspath(__file__))
    # Custom REACT-based component for recording client audio in browser
    build_dir = os.path.join(parent_dir, "st_audiorec/frontend/build")
    # specify directory and initialize st_audiorec object functionality
    st_audiorec = components.declare_component("st_audiorec", path=build_dir)

    # Create an instance of the component: STREAMLIT AUDIO RECORDER
    raw_audio_data = st_audiorec()  # raw_audio_data: stores all the data returned from the streamlit frontend
    wav_bytes = None                # wav_bytes: contains the recorded audio in .WAV format after conversion

    # the frontend returns raw audio data in the form of arraybuffer
    # (this arraybuffer is derived from web-media API WAV-blob data)

    if isinstance(raw_audio_data, dict):  # retrieve audio data
        with st.spinner('retrieving audio-recording...'):
            ind, raw_audio_data = zip(*raw_audio_data['arr'].items())
            ind = np.array(ind, dtype=int)  # convert to np array
            raw_audio_data = np.array(raw_audio_data)  # convert to np array
            sorted_ints = raw_audio_data[ind]
            stream = BytesIO(b"".join([int(v).to_bytes(1, "big") for v in sorted_ints]))
            # wav_bytes contains audio data in byte format, ready to be processed further
            wav_bytes = stream.read()

    return wav_bytes

def audio_rec_demo():
    
    wav_audio_data = st_audiorec()
    
    if wav_audio_data is not None:
        # display audio data as received on the Python side
        col_playback, col_space = st.columns([0.58,0.42])
        with col_playback:
            # print(type(wav_audio_data))
            # st.info("ë…¹ìŒ ì™„ë£Œ")
            # st.audio(wav_audio_data, format='audio/wav')
            wave_file = wave.open("output.wav", "wb")
            
    return wav_audio_data

def save_wave_file(filename, data, sample_width, sample_rate, channels):
    try:
        with wave.open(filename, 'wb') as wave_file:
            wave_file.setnchannels(channels)
            wave_file.setsampwidth(sample_width)
            wave_file.setframerate(sample_rate)
            wave_file.writeframes(data)
        
    except:
        # print("ë­ë‹ˆ")
        pass     
    

def wave_to_stt(input_lang):
    
    lang_dict = {
        'í•œêµ­(KOR)': 'ko-KR', 
        'ì˜ì–´(ENG)': 'en-US',
        'ë² íŠ¸ë‚¨(VNM)': 'vi-VN',
        'íƒœêµ­(THA)': 'th-TH',
        'ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„(UZB)': 'uz-UZ',
        'ì¸ë„ë„¤ì‹œì•„(IDN)': 'id-ID',
        'ì¤‘êµ­(CHN)': 'zh',
        'ì¼ë³¸(JPN)': 'ja-JP'   
        }
    
    target = lang_dict[input_lang]
    
    filename = "output.wav"

    # Create an instance of the Recognizer class
    recognizer = sr.Recognizer()

    # Load the wave file
    with sr.AudioFile(filename) as source:
        audio = recognizer.record(source)  # Read the entire audio file

    response = {
        "success": True,
        "error": None,
        "transcription": None
        }
    
    # Perform speech recognition
    try:
        response["transcription"] = recognizer.recognize_google(audio, language=target, show_all=True)
        os.remove('output.wav')
        return response
    except sr.RequestError:
        # API was unreachable or unresponsive
        response["success"] = False
        response["error"] = "API unavailable"
    except sr.UnknownValueError:
        # speech was unintelligible
        response["error"] = "Unable to recognize speech"
    
    

def han_get_safety_keywords(txt, risk_words):
    hannanum = Hannanum()
    word_dict = {}
    risk_words = risk_words
    try:
        lines = txt.split("\n")
    
        for line in lines:
            malist = hannanum.pos(line)
            for word in malist:
                if word[1] == "N":
                    if not (word[0] in word_dict):
                        word_dict[word[0]]=0
                    word_dict[word[0]] +=1 

        for word in word_dict.copy():
            if word not in risk_words:
                del word_dict[word]
        
        
        keys = sorted(word_dict.items(), key=lambda x:x[1], reverse=True)
        df = pd.DataFrame(keys, columns=['Word', 'Count'])
        r_df = df[df["Count"]>=1]
        return r_df
    except:
        pass


       
async def trans_keyword(stt_result, input_lang, target_langs):
    
    st.markdown("##### ğŸŒ»:green[ë²ˆì—­ ê²°ê³¼] (ì˜ì–´ë¥¼ ê±°ì³ 3êµ­ì–´ë¡œ ë²ˆì—­)")
    
    target_dict = {
        'ì˜ì–´(ENG)': 'en',
        'ë² íŠ¸ë‚¨(VNM)': 'vi',
        'íƒœêµ­(THA)': 'th',
        'ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„(UZB)': 'uz',
        'ì¸ë„ë„¤ì‹œì•„(IDN)': 'id',
        'ì¤‘êµ­(CHN)': 'zh-cn',       # chinese simplified : zh-cn, chinese traditional : zh-tw
        'ì¼ë³¸(JPN)': 'ja',
        'í•œêµ­(KOR)': 'ko'
        }
    
    selected_input_lang = target_dict[input_lang]
    selected_target_langs = [target_dict[i] for i in target_langs]
    target_input = stt_result
    
    try:
        translations = await asyncio.gather(*[trans(target_input, selected_input_lang, selected_target_lang) for selected_target_lang in selected_target_langs])
        
        for lang, translation in zip(target_langs, translations):
            st.markdown(f"ğŸ˜‰ **{lang}** : {translation}")
        
        return translations
    except:
        print("ë­ê¼¬?")
        pass

def get_visiting_count(val1, cnt):
    if val1 != None:
        cnt += 1
        return cnt


if __name__ == "__main__":   
    
    col001, col002 = st.columns([5.5, 4.5])
    with col001:     
    
        st.markdown("###### :red[AI Insight] Series - :blue[ì•ˆì „ìƒì‚°]ğŸ€ [beta service]")
        st.markdown("#### :green[ì™¸êµ­ì¸ ê·¼ë¡œì] ì‘ì—…ì§€ì‹œ :blue[í†µì—­ì§€ì›]")
        st.markdown("###### :violet[(AI Work Order Translation Service for Foreign Workers)]")
        st.write('\n')  # add vertical spacer
        
        st.error("ğŸŒˆ :red[**í¬ë¡¬ or ì‚¬íŒŒë¦¬**]ì—ì„œ ì˜¤í”ˆ~ ì¹´í†¡ ë§í¬ ê²½ìœ  ì˜¤í”ˆì‹œ ìš°ì¸¡ í•˜ë‹¨ ë²„íŠ¼ + ë‹¤ë¥¸ ë¸Œë¼ìš°ì € ì—´ê¸° (ë¬¸ì ë§í¬ëŠ” OK)")
        
        input_langs = ["í•œêµ­(KOR)", "ì˜ì–´(ENG)", "ë² íŠ¸ë‚¨(VNM)", "íƒœêµ­(THA)", "ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„(UZB)", "ì¸ë„ë„¤ì‹œì•„(IDN)", "ì¤‘êµ­(CHN)", "ì¼ë³¸(JPN)"]
        target_langs = ["ì˜ì–´(ENG)", "ë² íŠ¸ë‚¨(VNM)", "íƒœêµ­(THA)", "ìš°ì¦ˆë² í‚¤ìŠ¤íƒ„(UZB)", "ì¸ë„ë„¤ì‹œì•„(IDN)", "ì¤‘êµ­(CHN)", "ì¼ë³¸(JPN)", "í•œêµ­(KOR)"]
        selected_input_lang = st.selectbox("ğŸ“Œ **ì…ë ¥ ì–¸ì–´**(Input)ë¥¼ ì„ íƒí•˜ì„¸ìš” (ê¸°ë³¸ í•œêµ­ì–´)", input_langs)
        selected_target_lang = st.multiselect("ğŸ“Œ **ë²ˆì—­ ì–¸ì–´**(Output)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", target_langs, target_langs)
        
        st.warning("ğŸ‘¨â€ğŸ”§ ì™¸êµ­ì¸ ê·¼ë¡œì ì‘ì—…ì§€ì‹œëŠ” :red[**ì‰¬ìš´ ë‹¨ì–´ + í•œë¬¸ì¥**]ìœ¼ë¡œ ëª…í™•í•˜ê²Œ í•´ì£¼ì„¸ìš” :blue[**(Start~, Stop~ ë²„íŠ¼)**]")

        with st.container():
            data = audio_rec_demo()
                
            filename = "output.wav"
            sample_width = 2  # In bytes, for 16-bit audio
            sample_rate = 44100  # The number of samples per second (standard for audio CDs)
            channels = 2 # Stereo audio

            save_wave_file(filename, data, sample_width, sample_rate, channels)
            
            try:
                text = wave_to_stt(selected_input_lang)
                st.success(f"ğŸ“¢ì‘ì—… ì§€ì‹œ : {text['transcription']['alternative'][0]['transcript']}")
                revised_txt = st.text_area("ğŸ”„ ì•„ë˜ í…ìŠ¤íŠ¸ :blue[**ìˆ˜ì •**]ì‹œ ë‹¤ì‹œ ë²ˆì—­ (ìˆ˜ì •í›„ ê¸€ìƒì ì™¸ë¶€ í„°ì¹˜)", value = text['transcription']['alternative'][0]['transcript'] )
                
                with st.expander("ğŸ³ :blue[**All Cases of STT Review**] - ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜ ê²€í† "):
                    st.info(f"{text['transcription']['alternative']}")
                    st.markdown('''
                                **[AI í† ë§‰ ìƒì‹] STTë€ ë¬´ì—‡ì¸ê°€ìš”??**\n
                                :red[**STT**]ëŠ” Speech to Textì˜ ì•½ìë¡œì„œ ì‚¬ëŒì´ ë§í•˜ëŠ” ìŒì„± ì–¸ì–´ë¥¼ 
                                AI ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í•´ì„í•´ ê·¸ ë‚´ìš©ì„ ë¬¸ì ë°ì´í„°ë¡œ ì „í™˜í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ë©°,
                                Confidence Levelì´ ê°€ì¥ ë†’ì€ ê²°ê³¼ë¥¼ Best STTë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
                                STTëŠ” í–¥í›„ ìŒì„± ë°ì´í„° ê¸°ë°˜ ì—…ë¬´ ê°œì„  ë„êµ¬ë¡œ í™•ëŒ€ë  ì˜ˆì •ì…ë‹ˆë‹¤.                      
                                ''')
            except:
                pass
        st.markdown("---")
        
        
        try:
            best_stt = revised_txt
            result = asyncio.run(trans_keyword(best_stt, selected_input_lang, selected_target_lang))
            if result != None:
                name = "ë°•ë³´ê²€"
                data = {
                    "Name" : {"title": [{"text": {"content": name}}]},
                    }
                insert_data(data)
            
        except:
            pass
        st.markdown("---")
        
        mywords = pd.read_excel("mywords.xlsx")
        
        try:
            st.markdown("##### ğŸ’¥:red[ìœ„í—˜í‚¤ì›Œë“œ]- Hannanum Test")
            risk_words_list = mywords["mywords"].values
            keyword_df = han_get_safety_keywords(best_stt, risk_words_list)
            keyword_df
        except:
            st.markdown("í•´ë‹¹ì‚¬í•­ ì—†ìŒ(í…ŒìŠ¤íŠ¸ì¤‘)")
            pass
        
        st.markdown("---")

        st.error("âš¾ ***Created by :red[Advanced AI Team] in :blue[AI Center]***")
        st.markdown("###### ğŸ”’ ë³¸ ì„œë¹„ìŠ¤ëŠ” ìŒì„± ë° í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.markdown("###### ğŸ“§ Contact : jongbae.kim@ksoe.co.kr")
        st.markdown("###### ğŸ’– Supported by [Stefan](https://github.com/stefanrmmr/streamlit_audio_recorder), [Google](https://github.com/ssut/py-googletrans), [Konlpy](https://konlpy.org/ko/latest/index.html), etc.")
